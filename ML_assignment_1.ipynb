{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f13b825",
   "metadata": {},
   "source": [
    "Question 1 [10 points]\n",
    "Text classification is an example of Na ̈ıve Bayes application. You are required to classify the\n",
    "following statements, “a cup of hot coffee” and “a cone of ice cream”, given the categories Sunny\n",
    "and Rainy. The following is a training data:\n",
    "expression category\n",
    "it is raining rainy\n",
    "picnic on a hot afternoon sunny\n",
    "they wore sunglasses sunny\n",
    "going out with an umbrella rainy\n",
    "Given a training data, an objective of Na ̈ıve Bayes will be to compute P(sunny|a cone of\n",
    "ice cream) and P(rainy|a cup of hot coffee) and classify the statement as the category with a\n",
    "higher probability. A plausible approach is to create word features with an assumption that\n",
    "the occurrence of each word is an independent event. For example, P(a cup of hot coffee) =\n",
    "P(a)P(cup)P(of)P(hot)P(coffee)\n",
    "For the two expressions, our interest lies in classifying rightly for the two categories, what are\n",
    "the following probabilities according to Bayes’ Theorem? Please make sure to decompose the joint\n",
    "distribution with the conditional independence assumption (hint: no numerical values required).\n",
    "1. P(sunny|a cone of ice cream) = ?\n",
    "2. P(rainy|a cup of hot coffee) = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db00636",
   "metadata": {},
   "source": [
    "P(sunny|a cone of ice cream) = p(sunny)*p(a|sunny)*p(cone|sunny)*p(of|sunny)*p(ice|sunny)*p(cream|sunny)\n",
    "P(rainy|a cup of hot coffee) = p(rainy)*p(a|rainy)*p(cup|rainy)*p(of|rainy)*p(hot|rainy)*p(coffee|rainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781a4591",
   "metadata": {},
   "source": [
    "as per training data p(sunny) = 2/4 p(a) = 1/8 and we can ignore the rest of the words because they are not in training data\n",
    "\n",
    "P(sunny|a cone of ice cream) = 2/4*1/8 = 2/32 = 1/16 = 0.0625\n",
    "P(rainy|a cup of hot coffee) = 2/4*1/8 = 0.0625*0/8 = 0\n",
    "\n",
    "P(sunny|a cone of ice cream) has higher probability of happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df46f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "import heapq, random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Data structures useful for implementing SearchAgents\n",
    "\"\"\"\n",
    "\n",
    "class Stack:\n",
    "  \"A container with a last-in-first-out (LIFO) queuing policy.\"\n",
    "  def __init__(self):\n",
    "    self.list = []\n",
    "    \n",
    "  def push(self,item):\n",
    "    \"Push 'item' onto the stack\"\n",
    "    self.list.append(item)\n",
    "\n",
    "  def pop(self):\n",
    "    \"Pop the most recently pushed item from the stack\"\n",
    "    return self.list.pop()\n",
    "\n",
    "  def isEmpty(self):\n",
    "    \"Returns true if the stack is empty\"\n",
    "    return len(self.list) == 0\n",
    "\n",
    "class Queue:\n",
    "  \"A container with a first-in-first-out (FIFO) queuing policy.\"\n",
    "  def __init__(self):\n",
    "    self.list = []\n",
    "  \n",
    "  def push(self,item):\n",
    "    \"Enqueue the 'item' into the queue\"\n",
    "    self.list.insert(0,item)\n",
    "\n",
    "  def pop(self):\n",
    "    \"\"\"\n",
    "      Dequeue the earliest enqueued item still in the queue. This\n",
    "      operation removes the item from the queue.\n",
    "    \"\"\"\n",
    "    return self.list.pop()\n",
    "\n",
    "  def isEmpty(self):\n",
    "    \"Returns true if the queue is empty\"\n",
    "    return len(self.list) == 0\n",
    "  \n",
    "class PriorityQueue:\n",
    "  \"\"\"\n",
    "    Implements a priority queue data structure. Each inserted item\n",
    "    has a priority associated with it and the client is usually interested\n",
    "    in quick retrieval of the lowest-priority item in the queue. This\n",
    "    data structure allows O(1) access to the lowest-priority item.\n",
    "    \n",
    "    Note that this PriorityQueue does not allow you to change the priority\n",
    "    of an item.  However, you may insert the same item multiple times with\n",
    "    different priorities.\n",
    "  \"\"\"  \n",
    "  def  __init__(self):  \n",
    "    self.heap = []\n",
    "    \n",
    "  def push(self, item, priority):\n",
    "      pair = (priority,item)\n",
    "      heapq.heappush(self.heap,pair)\n",
    "\n",
    "  def pop(self):\n",
    "      (priority,item) = heapq.heappop(self.heap)\n",
    "      return item\n",
    "  \n",
    "  def isEmpty(self):\n",
    "    return len(self.heap) == 0\n",
    "\n",
    "class PriorityQueueWithFunction(PriorityQueue):\n",
    "  \"\"\"\n",
    "  Implements a priority queue with the same push/pop signature of the\n",
    "  Queue and the Stack classes. This is designed for drop-in replacement for\n",
    "  those two classes. The caller has to provide a priority function, which\n",
    "  extracts each item's priority.\n",
    "  \"\"\"  \n",
    "  def  __init__(self, priorityFunction):\n",
    "    \"priorityFunction (item) -> priority\"\n",
    "    self.priorityFunction = priorityFunction      # store the priority function\n",
    "    PriorityQueue.__init__(self)        # super-class initializer\n",
    "    \n",
    "  def push(self, item):\n",
    "    \"Adds an item to the queue with priority from the priority function\"\n",
    "    PriorityQueue.push(self, item, self.priorityFunction(item))\n",
    "\n",
    "    \n",
    "def manhattanDistance( xy1, xy2 ):\n",
    "  \"Returns the Manhattan distance between points xy1 and xy2\"\n",
    "  return abs( xy1[0] - xy2[0] ) + abs( xy1[1] - xy2[1] )\n",
    "\n",
    "\"\"\"\n",
    "  Data structures and functions useful for various course projects\n",
    "  \n",
    "  The search project should not need anything below this line.\n",
    "\"\"\"\n",
    "\n",
    "class Counter(dict):\n",
    "  \"\"\"\n",
    "  A counter keeps track of counts for a set of keys.\n",
    "  \n",
    "  The counter class is an extension of the standard python\n",
    "  dictionary type.  It is specialized to have number values  \n",
    "  (integers or floats), and includes a handful of additional\n",
    "  functions to ease the task of counting data.  In particular, \n",
    "  all keys are defaulted to have value 0.  Using a dictionary:\n",
    "  \n",
    "  a = {}\n",
    "  print a['test']\n",
    "  \n",
    "  would give an error, while the Counter class analogue:\n",
    "    \n",
    "  >>> a = Counter()\n",
    "  >>> print a['test']\n",
    "  0\n",
    "\n",
    "  returns the default 0 value. Note that to reference a key \n",
    "  that you know is contained in the counter, \n",
    "  you can still use the dictionary syntax:\n",
    "    \n",
    "  >>> a = Counter()\n",
    "  >>> a['test'] = 2\n",
    "  >>> print a['test']\n",
    "  2\n",
    "  \n",
    "  This is very useful for counting things without initializing their counts,\n",
    "  see for example:\n",
    "  \n",
    "  >>> a['blah'] += 1\n",
    "  >>> print a['blah']\n",
    "  1\n",
    "  \n",
    "  The counter also includes additional functionality useful in implementing\n",
    "  the classifiers for this assignment.  Two counters can be added,\n",
    "  subtracted or multiplied together.  See below for details.  They can\n",
    "  also be normalized and their total count and arg max can be extracted.\n",
    "  \"\"\"\n",
    "  def __getitem__(self, idx):\n",
    "    self.setdefault(idx, 0)\n",
    "    return dict.__getitem__(self, idx)\n",
    "\n",
    "  def incrementAll(self, keys, count):\n",
    "    \"\"\"\n",
    "    Increments all elements of keys by the same count.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> a.incrementAll(['one','two', 'three'], 1)\n",
    "    >>> a['one']\n",
    "    1\n",
    "    >>> a['two']\n",
    "    1\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "      self[key] += count\n",
    "  \n",
    "  def argMax(self):\n",
    "    \"\"\"\n",
    "    Returns the key with the highest value.\n",
    "    \"\"\"\n",
    "    if len(list(self.keys())) == 0: return None\n",
    "    all = list(self.items())\n",
    "    values = [x[1] for x in all]\n",
    "    maxIndex = values.index(max(values))\n",
    "    return all[maxIndex][0]\n",
    "  \n",
    "  def sortedKeys(self):\n",
    "    \"\"\"\n",
    "    Returns a list of keys sorted by their values.  Keys\n",
    "    with the highest values will appear first.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> a['first'] = -2\n",
    "    >>> a['second'] = 4\n",
    "    >>> a['third'] = 1\n",
    "    >>> a.sortedKeys()\n",
    "    ['second', 'third', 'first']\n",
    "    \"\"\"\n",
    "    sortedItems = list(self.items())\n",
    "    compare = lambda x, y:  sign(y[1] - x[1])\n",
    "    sortedItems.sort(cmp=compare)\n",
    "    return [x[0] for x in sortedItems]\n",
    "  \n",
    "  def totalCount(self):\n",
    "    \"\"\"\n",
    "    Returns the sum of counts for all keys.\n",
    "    \"\"\"\n",
    "    return sum(self.values())\n",
    "  \n",
    "  def normalize(self):\n",
    "    \"\"\"\n",
    "    Edits the counter such that the total count of all\n",
    "    keys sums to 1.  The ratio of counts for all keys\n",
    "    will remain the same. Note that normalizing an empty \n",
    "    Counter will result in an error.\n",
    "    \"\"\"\n",
    "    total = float(self.totalCount())\n",
    "    if total == 0: return\n",
    "    for key in list(self.keys()):\n",
    "      self[key] = self[key] / total\n",
    "      \n",
    "  def divideAll(self, divisor):\n",
    "    \"\"\"\n",
    "    Divides all counts by divisor\n",
    "    \"\"\"\n",
    "    divisor = float(divisor)\n",
    "    for key in self:\n",
    "      self[key] /= divisor\n",
    "\n",
    "  def copy(self):\n",
    "    \"\"\"\n",
    "    Returns a copy of the counter\n",
    "    \"\"\"\n",
    "    return Counter(dict.copy(self))\n",
    "  \n",
    "  def __mul__(self, y ):\n",
    "    \"\"\"\n",
    "    Multiplying two counters gives the dot product of their vectors where\n",
    "    each unique label is a vector element.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> b = Counter()\n",
    "    >>> a['first'] = -2\n",
    "    >>> a['second'] = 4\n",
    "    >>> b['first'] = 3\n",
    "    >>> b['second'] = 5\n",
    "    >>> a['third'] = 1.5\n",
    "    >>> a['fourth'] = 2.5\n",
    "    >>> a * b\n",
    "    14\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    x = self\n",
    "    if len(x) > len(y):\n",
    "      x,y = y,x\n",
    "    for key in x:\n",
    "      if key not in y:\n",
    "        continue\n",
    "      sum += x[key] * y[key]      \n",
    "    return sum\n",
    "      \n",
    "  def __radd__(self, y):\n",
    "    \"\"\"\n",
    "    Adding another counter to a counter increments the current counter\n",
    "    by the values stored in the second counter.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> b = Counter()\n",
    "    >>> a['first'] = -2\n",
    "    >>> a['second'] = 4\n",
    "    >>> b['first'] = 3\n",
    "    >>> b['third'] = 1\n",
    "    >>> a += b\n",
    "    >>> a['first']\n",
    "    1\n",
    "    \"\"\" \n",
    "    for key, value in list(y.items()):\n",
    "      self[key] += value   \n",
    "      \n",
    "  def __add__( self, y ):\n",
    "    \"\"\"\n",
    "    Adding two counters gives a counter with the union of all keys and\n",
    "    counts of the second added to counts of the first.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> b = Counter()\n",
    "    >>> a['first'] = -2\n",
    "    >>> a['second'] = 4\n",
    "    >>> b['first'] = 3\n",
    "    >>> b['third'] = 1\n",
    "    >>> (a + b)['first']\n",
    "    1\n",
    "    \"\"\"\n",
    "    addend = Counter()\n",
    "    for key in self:\n",
    "      if key in y:\n",
    "        addend[key] = self[key] + y[key]\n",
    "      else:\n",
    "        addend[key] = self[key]\n",
    "    for key in y:\n",
    "      if key in self:\n",
    "        continue\n",
    "      addend[key] = y[key]\n",
    "    return addend\n",
    "    \n",
    "  def __sub__( self, y ):\n",
    "    \"\"\"\n",
    "    Subtracting a counter from another gives a counter with the union of all keys and\n",
    "    counts of the second subtracted from counts of the first.\n",
    "    \n",
    "    >>> a = Counter()\n",
    "    >>> b = Counter()\n",
    "    >>> a['first'] = -2\n",
    "    >>> a['second'] = 4\n",
    "    >>> b['first'] = 3\n",
    "    >>> b['third'] = 1\n",
    "    >>> (a - b)['first']\n",
    "    -5\n",
    "    \"\"\"      \n",
    "    addend = Counter()\n",
    "    for key in self:\n",
    "      if key in y:\n",
    "        addend[key] = self[key] - y[key]\n",
    "      else:\n",
    "        addend[key] = self[key]\n",
    "    for key in y:\n",
    "      if key in self:\n",
    "        continue\n",
    "      addend[key] = -1 * y[key]\n",
    "    return addend\n",
    "    \n",
    "def raiseNotDefined():\n",
    "  print(\"Method not implemented: %s\" % inspect.stack()[1][3])    \n",
    "  sys.exit(1)\n",
    "\n",
    "def normalize(vectorOrCounter):\n",
    "  \"\"\"\n",
    "  normalize a vector or counter by dividing each value by the sum of all values\n",
    "  \"\"\"\n",
    "  normalizedCounter = Counter()\n",
    "  if type(vectorOrCounter) == type(normalizedCounter):\n",
    "    counter = vectorOrCounter\n",
    "    total = float(counter.totalCount())\n",
    "    if total == 0: return counter\n",
    "    for key in list(counter.keys()):\n",
    "      value = counter[key]\n",
    "      normalizedCounter[key] = value / total\n",
    "    return normalizedCounter\n",
    "  else:\n",
    "    vector = vectorOrCounter\n",
    "    s = float(sum(vector))\n",
    "    if s == 0: return vector\n",
    "    return [el / s for el in vector]\n",
    "                \n",
    "def nSample(distribution, values, n):\n",
    "  if sum(distribution) != 1:\n",
    "    distribution = normalize(distribution)\n",
    "  rand = [random.random() for i in range(n)]\n",
    "  rand.sort()\n",
    "  samples = []\n",
    "  samplePos, distPos, cdf = 0,0, distribution[0]\n",
    "  while samplePos < n:\n",
    "    if rand[samplePos] < cdf:\n",
    "      samplePos += 1\n",
    "      samples.append(values[distPos])\n",
    "    else:\n",
    "      distPos += 1\n",
    "      cdf += distribution[distPos]\n",
    "  return samples\n",
    "    \n",
    "def sample(distribution, values = None):\n",
    "  if type(distribution) == Counter: \n",
    "    items = list(distribution.items())\n",
    "    distribution = [i[1] for i in items] \n",
    "    values = [i[0] for i in items] \n",
    "  if sum(distribution) != 1:\n",
    "    distribution = normalize(distribution)\n",
    "  choice = random.random()\n",
    "  i, total= 0, distribution[0]\n",
    "  while choice > total:\n",
    "    i += 1\n",
    "    total += distribution[i]\n",
    "  return values[i]\n",
    "\n",
    "def sampleFromCounter(ctr):\n",
    "  items = list(ctr.items())\n",
    "  return sample([v for k,v in items], [k for k,v in items])\n",
    "\n",
    "def getProbability(value, distribution, values):\n",
    "  \"\"\"\n",
    "    Gives the probability of a value under a discrete distribution\n",
    "    defined by (distributions, values).\n",
    "  \"\"\"\n",
    "  total = 0.0\n",
    "  for prob, val in zip(distribution, values):\n",
    "    if val == value:\n",
    "      total += prob\n",
    "  return total\n",
    "\n",
    "def flipCoin( p ):\n",
    "  r = random.random()\n",
    "  return r < p \n",
    "\n",
    "def chooseFromDistribution( distribution ):\n",
    "  \"Takes either a counter or a list of (prob, key) pairs and samples\"\n",
    "  if type(distribution) == dict or type(distribution) == Counter:\n",
    "    return sample(distribution)\n",
    "  r = random.random()\n",
    "  base = 0.0\n",
    "  for prob, element in distribution:\n",
    "    base += prob\n",
    "    if r <= base: return element\n",
    "    \n",
    "def nearestPoint( pos ):\n",
    "  \"\"\"\n",
    "  Finds the nearest grid point to a position (discretizes).\n",
    "  \"\"\"\n",
    "  ( current_row, current_col ) = pos\n",
    "\n",
    "  grid_row = int( current_row + 0.5 ) \n",
    "  grid_col = int( current_col + 0.5 ) \n",
    "  return ( grid_row, grid_col )     \n",
    "\n",
    "def sign( x ):\n",
    "  \"\"\"\n",
    "  Returns 1 or -1 depending on the sign of x\n",
    "  \"\"\"\n",
    "  if( x >= 0 ):\n",
    "    return 1\n",
    "  else:\n",
    "    return -1\n",
    "\n",
    "def arrayInvert(array):\n",
    "  \"\"\"\n",
    "  Inverts a matrix stored as a list of lists.\n",
    "  \"\"\"\n",
    "  result = [[] for i in array]\n",
    "  for outer in array:\n",
    "    for inner in range(len(outer)):\n",
    "      result[inner].append(outer[inner])\n",
    "  return result\n",
    "\n",
    "def matrixAsList( matrix, value = True ):\n",
    "  \"\"\"\n",
    "  Turns a matrix into a list of coordinates matching the specified value\n",
    "  \"\"\"\n",
    "  rows, cols = len( matrix ), len( matrix[0] )\n",
    "  cells = []\n",
    "  for row in range( rows ):\n",
    "    for col in range( cols ):\n",
    "      if matrix[row][col] == value:\n",
    "        cells.append( ( row, col ) )\n",
    "  return cells\n",
    "\n",
    "def lookup(name, namespace):\n",
    "  \"\"\"\n",
    "  Get a method or class from any imported module from its name.\n",
    "  Usage: lookup(functionName, globals())\n",
    "  \"\"\"\n",
    "  dots = name.count('.')\n",
    "  if dots > 0:\n",
    "    moduleName, objName = '.'.join(name.split('.')[:-1]), name.split('.')[-1]\n",
    "    module = __import__(moduleName)\n",
    "    return getattr(module, objName)\n",
    "  else:\n",
    "    modules = [obj for obj in list(namespace.values()) if str(type(obj)) == \"<type 'module'>\"]\n",
    "    options = [getattr(module, name) for module in modules if name in dir(module)]\n",
    "    options += [obj[1] for obj in list(namespace.items()) if obj[0] == name ]\n",
    "    if len(options) == 1: return options[0]\n",
    "    if len(options) > 1: raise Exception('Name conflict for %s')\n",
    "    raise Exception('%s not found as a method or class' % name)\n",
    "\n",
    "def pause():\n",
    "  \"\"\"\n",
    "  Pauses the output stream awaiting user feedback.\n",
    "  \"\"\"\n",
    "  print(\"<Press enter/return to continue>\")\n",
    "  input()\n",
    "  \n",
    "  \n",
    "## code to handle timeouts\n",
    "import signal\n",
    "class TimeoutFunctionException(Exception):\n",
    "    \"\"\"Exception to raise on a timeout\"\"\"\n",
    "    pass\n",
    "\n",
    "class TimeoutFunction:\n",
    "\n",
    "    def __init__(self, function, timeout):\n",
    "        \"timeout must be at least 1 second. WHY??\"\n",
    "        self.timeout = timeout\n",
    "        self.function = function\n",
    "\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutFunctionException()\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        if not 'SIGALRM' in dir(signal):\n",
    "            return self.function(*args)\n",
    "        old = signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.timeout)\n",
    "        try:\n",
    "            result = self.function(*args)\n",
    "        finally:\n",
    "            signal.signal(signal.SIGALRM, old)\n",
    "        signal.alarm(0)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289a7b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line ?, in __main__.Counter\n",
      "Failed example:\n",
      "    print a['test']\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\ProgramData\\anaconda3\\Lib\\doctest.py\", line 1351, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"<doctest __main__.Counter[1]>\", line 1\n",
      "        print a['test']\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\n",
      "**********************************************************************\n",
      "File \"__main__\", line ?, in __main__.Counter\n",
      "Failed example:\n",
      "    print a['test']\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\ProgramData\\anaconda3\\Lib\\doctest.py\", line 1351, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"<doctest __main__.Counter[4]>\", line 1\n",
      "        print a['test']\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\n",
      "**********************************************************************\n",
      "File \"__main__\", line ?, in __main__.Counter\n",
      "Failed example:\n",
      "    print a['blah']\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\ProgramData\\anaconda3\\Lib\\doctest.py\", line 1351, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"<doctest __main__.Counter[6]>\", line 1\n",
      "        print a['blah']\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    SyntaxError: Missing parentheses in call to 'print'. Did you mean print(...)?\n",
      "**********************************************************************\n",
      "File \"__main__\", line 176, in __main__.Counter.sortedKeys\n",
      "Failed example:\n",
      "    a.sortedKeys()\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"C:\\ProgramData\\anaconda3\\Lib\\doctest.py\", line 1351, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest __main__.Counter.sortedKeys[4]>\", line 1, in <module>\n",
      "        a.sortedKeys()\n",
      "      File \"C:\\Users\\minat\\AppData\\Local\\Temp\\ipykernel_5504\\341542885.py\", line 181, in sortedKeys\n",
      "        sortedItems.sort(cmp=compare)\n",
      "    TypeError: 'cmp' is an invalid keyword argument for sort()\n",
      "**********************************************************************\n",
      "2 items had failures:\n",
      "   3 of   7 in __main__.Counter\n",
      "   1 of   5 in __main__.Counter.sortedKeys\n",
      "***Test Failed*** 4 failures.\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                +++++##+    \n",
      "        +++++######+###+    \n",
      "       +##########+++++     \n",
      "        #######+##          \n",
      "        +++###  ++          \n",
      "           +#+              \n",
      "           +#+              \n",
      "            +#+             \n",
      "            +##++           \n",
      "             +###++         \n",
      "              ++##++        \n",
      "                +##+        \n",
      "                 ###+       \n",
      "              +++###        \n",
      "            ++#####+        \n",
      "          ++######+         \n",
      "        ++######+           \n",
      "       +######+             \n",
      "    ++######+               \n",
      "    +####++                 \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                +++++##+    \n",
      "        +++++######+###+    \n",
      "       +##########+++++     \n",
      "        #######+##          \n",
      "        +++###  ++          \n",
      "           +#+              \n",
      "           +#+              \n",
      "            +#+             \n",
      "            +##++           \n",
      "             +###++         \n",
      "              ++##++        \n",
      "                +##+        \n",
      "                 ###+       \n",
      "              +++###        \n",
      "            ++#####+        \n",
      "          ++######+         \n",
      "        ++######+           \n",
      "       +######+             \n",
      "    ++######+               \n",
      "    +####++                 \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "28\n",
      "28\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'getAsciiString', 'getPixel', 'getPixels', 'height', 'pixels', 'width']\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Constants\n",
    "DATUM_WIDTH = 0 # in pixels\n",
    "DATUM_HEIGHT = 0 # in pixels\n",
    "\n",
    "## Module Classes\n",
    "\n",
    "class Datum:\n",
    "  \"\"\"\n",
    "  A datum is a pixel-level encoding of digits or face/non-face edge maps.\n",
    "\n",
    "  Digits are from the MNIST dataset and face images are from the \n",
    "  easy-faces and background categories of the Caltech 101 dataset.\n",
    "  \n",
    "  \n",
    "  Each digit is 28x28 pixels, and each face/non-face image is 60x74 \n",
    "  pixels, each pixel can take the following values:\n",
    "    0: no edge (blank)\n",
    "    1: gray pixel (+) [used for digits only]\n",
    "    2: edge [for face] or black pixel [for digit] (#)\n",
    "    \n",
    "  Pixel data is stored in the 2-dimensional array pixels, which\n",
    "  maps to pixels on a plane according to standard euclidean axes\n",
    "  with the first dimension denoting the horizontal and the second\n",
    "  the vertical coordinate:\n",
    "    \n",
    "    28 # # # #      #  #\n",
    "    27 # # # #      #  #\n",
    "     .\n",
    "     .\n",
    "     .\n",
    "     3 # # + #      #  #\n",
    "     2 # # # #      #  #\n",
    "     1 # # # #      #  #\n",
    "     0 # # # #      #  #\n",
    "       0 1 2 3 ... 27 28\n",
    "   \n",
    "  For example, the + in the above diagram is stored in pixels[2][3], or\n",
    "  more generally pixels[column][row].\n",
    "       \n",
    "  The contents of the representation can be accessed directly\n",
    "  via the getPixel and getPixels methods.\n",
    "  \"\"\"\n",
    "  def __init__(self, data,width,height):\n",
    "    \"\"\"\n",
    "    Create a new datum from file input (standard MNIST encoding).\n",
    "    \"\"\"\n",
    "    DATUM_HEIGHT = height\n",
    "    DATUM_WIDTH=width\n",
    "    self.height = DATUM_HEIGHT\n",
    "    self.width = DATUM_WIDTH\n",
    "    if data == None:\n",
    "      data = [[' ' for i in range(DATUM_WIDTH)] for j in range(DATUM_HEIGHT)] \n",
    "    self.pixels = arrayInvert(convertToInteger(data)) \n",
    "    \n",
    "  def getPixel(self, column, row):\n",
    "    \"\"\"\n",
    "    Returns the value of the pixel at column, row as 0, or 1.\n",
    "    \"\"\"\n",
    "    return self.pixels[column][row]\n",
    "      \n",
    "  def getPixels(self):\n",
    "    \"\"\"\n",
    "    Returns all pixels as a list of lists.\n",
    "    \"\"\"\n",
    "    return self.pixels    \n",
    "      \n",
    "  def getAsciiString(self):\n",
    "    \"\"\"\n",
    "    Renders the data item as an ascii image.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    data = arrayInvert(self.pixels)\n",
    "    for row in data:\n",
    "      ascii = list(map(asciiGrayscaleConversionFunction, row))\n",
    "      rows.append( \"\".join(ascii) )\n",
    "    return \"\\n\".join(rows)\n",
    "    \n",
    "  def __str__(self):\n",
    "    return self.getAsciiString()\n",
    "    \n",
    "\n",
    "\n",
    "# Data processing, cleanup and display functions\n",
    "    \n",
    "def loadDataFile(filename, n,width,height):\n",
    "  \"\"\"\n",
    "  Reads n data images from a file and returns a list of Datum objects.\n",
    "  \n",
    "  (Return less then n items if the end of file is encountered).\n",
    "  \"\"\"\n",
    "  DATUM_WIDTH=width\n",
    "  DATUM_HEIGHT=height\n",
    "  fin = readlines(filename)\n",
    "  fin.reverse()\n",
    "  items = []\n",
    "  for i in range(n):\n",
    "    data = []\n",
    "    for j in range(height):\n",
    "      data.append(list(fin.pop()))\n",
    "    if len(data[0]) < DATUM_WIDTH-1:\n",
    "      # we encountered end of file...\n",
    "      print(\"Truncating at %d examples (maximum)\" % i)\n",
    "      break\n",
    "    items.append(Datum(data,DATUM_WIDTH,DATUM_HEIGHT))\n",
    "  return items\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "def readlines(filename):\n",
    "  \"Opens a file or reads it from the zip archive data.zip\"\n",
    "  if(os.path.exists(filename)): \n",
    "    return [l[:-1] for l in open(filename).readlines()]\n",
    "  else: \n",
    "    z = zipfile.ZipFile('data.zip')\n",
    "    return z.read(filename).split('\\n')\n",
    "    \n",
    "def loadLabelsFile(filename, n):\n",
    "  \"\"\"\n",
    "  Reads n labels from a file and returns a list of integers.\n",
    "  \"\"\"\n",
    "  fin = readlines(filename)\n",
    "  labels = []\n",
    "  for line in fin[:min(n, len(fin))]:\n",
    "    if line == '':\n",
    "        break\n",
    "    labels.append(int(line))\n",
    "  return labels\n",
    "  \n",
    "def asciiGrayscaleConversionFunction(value):\n",
    "  \"\"\"\n",
    "  Helper function for display purposes.\n",
    "  \"\"\"\n",
    "  if(value == 0):\n",
    "    return ' '\n",
    "  elif(value == 1):\n",
    "    return '+'\n",
    "  elif(value == 2):\n",
    "    return '#'    \n",
    "    \n",
    "def IntegerConversionFunction(character):\n",
    "  \"\"\"\n",
    "  Helper function for file reading.\n",
    "  \"\"\"\n",
    "  if(character == ' '):\n",
    "    return 0\n",
    "  elif(character == '+'):\n",
    "    return 1\n",
    "  elif(character == '#'):\n",
    "    return 2    \n",
    "\n",
    "def convertToInteger(data):\n",
    "  \"\"\"\n",
    "  Helper function for file reading.\n",
    "  \"\"\"\n",
    "  if type(data) != type([]):\n",
    "    return IntegerConversionFunction(data)\n",
    "  else:\n",
    "    return list(map(convertToInteger, data))\n",
    "\n",
    "# Testing\n",
    "\n",
    "def _test():\n",
    "  import doctest\n",
    "  doctest.testmod() # Test the interactive sessions in function comments\n",
    "  n = 1\n",
    "#  items = loadDataFile(\"facedata/facedatatrain\", n,60,70)\n",
    "#  labels = loadLabelsFile(\"facedata/facedatatrainlabels\", n)\n",
    "  items = loadDataFile(\"trainingimages\", n,28,28)\n",
    "  labels = loadLabelsFile(\"traininglabels\", n)\n",
    "  for i in range(1):\n",
    "    print(items[i])\n",
    "    print(items[i])\n",
    "    print((items[i].height))\n",
    "    print((items[i].width))\n",
    "    print(dir(items[i]))\n",
    "    print(items[i].getPixels())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  _test()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6c4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the abstract class ClassificationMethod\n",
    "\n",
    "class ClassificationMethod:\n",
    "  \"\"\"\n",
    "  ClassificationMethod is the abstract superclass of \n",
    "   - MostFrequentClassifier\n",
    "   - NaiveBayesClassifier\n",
    " \n",
    "  As such, you need not add any code to this file.  You can write\n",
    "  all of your implementation code in the files for the individual\n",
    "  classification methods listed above.\n",
    "  \"\"\"\n",
    "  def __init__(self, legalLabels):\n",
    "    \"\"\"\n",
    "    For digits dataset, the set of legal labels will be 0,1,..,9\n",
    "    For faces dataset, the set of legal labels will be 0 (non-face) or 1 (face)\n",
    "    \"\"\"\n",
    "    self.legalLabels = legalLabels\n",
    "    \n",
    "    \n",
    "  def train(self, trainingData, trainingLabels, validationData, validationLabels):\n",
    "    \"\"\"\n",
    "    This is the supervised training function for the classifier.  Two sets of \n",
    "    labeled data are passed in: a large training set and a small validation set.\n",
    "    \n",
    "    Many types of classifiers have a common training structure in practice: using\n",
    "    training data for the main supervised training loop but tuning certain parameters\n",
    "    with a small held-out validation set.\n",
    "\n",
    "    For some classifiers (naive Bayes), you will need to return the parameters' \n",
    "    values after traning and tuning step.\n",
    "    \n",
    "    To make the classifier generic to multiple problems, the data should be represented\n",
    "    as lists of Counters containing feature descriptions and their counts.\n",
    "    \"\"\"\n",
    "    abstract\n",
    "    \n",
    "  def classify(self, data):\n",
    "    \"\"\"\n",
    "    This function returns a list of labels, each drawn from the set of legal labels\n",
    "    provided to the classifier upon construction.\n",
    "\n",
    "    To make the classifier generic to multiple problems, the data should be represented\n",
    "    as lists of Counters containing feature descriptions and their counts.\n",
    "    \"\"\"\n",
    "    abstract\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531f4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MostFrequentClassifier(ClassificationMethod):\n",
    "  \"\"\"\n",
    "  The MostFrequentClassifier is a very simple classifier: for\n",
    "  every test instance presented to it, the classifier returns\n",
    "  the label that was seen most often in the training data.\n",
    "  \"\"\"\n",
    "  def __init__(self, legalLabels):\n",
    "    self.guess = None\n",
    "    self.type = \"mostfrequent\"\n",
    "  \n",
    "  def train(self, data, labels, validationData, validationLabels):\n",
    "    \"\"\"\n",
    "    Find the most common label in the training data.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    counter.incrementAll(labels, 1)\n",
    "    self.guess = counter.argMax()\n",
    "  \n",
    "  def classify(self, testData):\n",
    "    \"\"\"\n",
    "    Classify all test data as the most common label.\n",
    "    \"\"\"\n",
    "    return [self.guess for i in testData]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b32e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "# import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier(ClassificationMethod):\n",
    "  \"\"\"\n",
    "  See the project description for the specifications of the Naive Bayes classifier.\n",
    "  \n",
    "  Note that the variable 'datum' in this code refers to a counter of features\n",
    "  (not to a raw samples.Datum).\n",
    "  \"\"\"\n",
    "  def __init__(self, legalLabels):\n",
    "    self.legalLabels = legalLabels\n",
    "    self.type = \"naivebayes\"\n",
    "    self.k = 1 # this is the smoothing parameter, ** use it in your train method **\n",
    "    self.automaticTuning = False # Look at this flag to decide whether to choose k automatically ** use this in your train method **\n",
    "    \n",
    "  def setSmoothing(self, k):\n",
    "    \"\"\"\n",
    "    This is used by the main method to change the smoothing parameter before training.\n",
    "    Do not modify this method.\n",
    "    \"\"\"\n",
    "    self.k = k\n",
    "\n",
    "  def train(self, trainingData, trainingLabels, validationData, validationLabels):\n",
    "    \"\"\"\n",
    "    Outside shell to call your method. Do not modify this method.\n",
    "    \"\"\"  \n",
    "      \n",
    "    self.features = list(trainingData[0].keys()) # this could be useful for your code later... \n",
    "    \n",
    "    if (self.automaticTuning):\n",
    "        kgrid = [0.001, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 50]\n",
    "    else:\n",
    "        kgrid = [self.k]\n",
    "        \n",
    "    self.trainAndTune(trainingData, trainingLabels, validationData, validationLabels, kgrid)\n",
    "      \n",
    "  def trainAndTune(self, trainingData, trainingLabels, validationData, validationLabels, kgrid):\n",
    "    \"\"\"\n",
    "    Trains the classifier by collecting counts over the training data, and\n",
    "    stores the Laplace smoothed estimates so that they can be used to classify.\n",
    "    Evaluate each value of k in kgrid to choose the smoothing parameter \n",
    "    that gives the best accuracy on the held-out validationData.\n",
    "    \n",
    "    trainingData and validationData are lists of feature Counters.  The corresponding\n",
    "    label lists contain the correct label for each datum.\n",
    "    \n",
    "    To get the list of all possible features or labels, use self.features and \n",
    "    self.legalLabels.\n",
    "    \"\"\"\n",
    "\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "\n",
    "    # how likely the labels shows up in training data\n",
    "    count=0\n",
    "    self.prior = Counter()\n",
    "    for label in self.legalLabels:\n",
    "      for y in trainingLabels:\n",
    "          if (label == y) is True:\n",
    "            count+=1\n",
    "      self.prior[label] =count/len(trainingLabels)\n",
    "      count = 0\n",
    "\n",
    "    counts = {}\n",
    "    totals = {}\n",
    "    for label in self.features:\n",
    "        counts[label] = {0: Counter(), 1: Counter()}\n",
    "        totals[label] = Counter()\n",
    "                 \n",
    "    # Calculate totals and counts\n",
    "    for i, data in enumerate(trainingData):\n",
    "        y = trainingLabels[i]\n",
    "        for key, value in list(data.items()):\n",
    "\n",
    "            counts[key][value][y] += 1.0\n",
    "            totals[key][y] += 1.0 \n",
    "            \n",
    "    bestConditionals = {}\n",
    "    # bestAccuracy = None\n",
    "    bestAccuracy = 0\n",
    "    # Evaluate each k, and use the one that yields the best accuracy\n",
    "    for k in kgrid:\n",
    "        correct = 0\n",
    "        conditionals = {}            \n",
    "        for feature in self.features:\n",
    "            conditionals[feature] = {0: Counter(), 1: Counter()}\n",
    "            \n",
    "        # Run Laplace smoothing\n",
    "        for feature in self.features:\n",
    "            for value in [0, 1]:\n",
    "                for y in self.legalLabels:\n",
    "                    conditionals[feature][value][y] = (counts[feature][value][y] + k) / (totals[feature][y] + k * 2)\n",
    "          \n",
    "        # Check the accuracy associated with this k\n",
    "        self.conditionals = conditionals              \n",
    "        guesses = self.classify(validationData)\n",
    "        for i, guess in enumerate(guesses):\n",
    "            correct += (validationLabels[i] == guess and 1.0 or 0.0)\n",
    "        accuracy = correct / len(guesses)\n",
    "        \n",
    "        # Keep the best k so far\n",
    "        # if accuracy > bestAccuracy or bestAccuracy is None:\n",
    "        if accuracy > bestAccuracy:\n",
    "          bestAccuracy = accuracy\n",
    "          bestConditionals = conditionals\n",
    "          self.k = k\n",
    "            \n",
    "    self.conditionals = bestConditionals\n",
    "\n",
    "    # raiseNotDefined()\n",
    "    \n",
    "        \n",
    "  def classify(self, testData):\n",
    "    \"\"\"\n",
    "    Classify the data based on the posterior distribution over labels.\n",
    "    \n",
    "    You shouldn't modify this method.\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    self.posteriors = [] # Log posteriors are stored for later data analysis (autograder).\n",
    "    for datum in testData:\n",
    "      posterior = self.calculateLogJointProbabilities(datum)\n",
    "      guesses.append(posterior.argMax())\n",
    "      self.posteriors.append(posterior)\n",
    "    return guesses\n",
    "      \n",
    "  def calculateLogJointProbabilities(self, datum):\n",
    "    \"\"\"\n",
    "    Returns the log-joint distribution over legal labels and the datum.\n",
    "    Each log-probability should be stored in the log-joint counter, e.g.    \n",
    "    logJoint[3] = <Estimate of log( P(Label = 3, datum) )>\n",
    "    \"\"\"\n",
    "    logJoint = Counter()\n",
    "    \n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    \n",
    "    for y in self.legalLabels:\n",
    "      logJoint[y] = math.log(self.prior[y])\n",
    "      for conditional in self.conditionals:\n",
    "        prob = self.conditionals[conditional][datum[conditional]][y]\n",
    "        logJoint[y] += (prob and math.log(prob) or 0.0)\n",
    "\n",
    "\n",
    "    # raiseNotDefined()\n",
    "    return logJoint\n",
    "\n",
    "    \n",
    "\n",
    "  def findHighOddsFeatures(self, label1, label2):\n",
    "    \"\"\"\n",
    "    Returns the 100 best features for the odds ratio:\n",
    "            P(feature=1 | label1)/P(feature=1 | label2) \n",
    "    \"\"\"\n",
    "    featuresOdds = []\n",
    "        \n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    logJoint = util.Counter()\n",
    "    for y in self.legalLabels:\n",
    "      logJoint[y] = math.log(self.prior[y])\n",
    "      for conditional in self.conditionals:\n",
    "        prob = (self.conditionals[conditional][label1[conditional]][y])/(self.conditionals[conditional][label2[conditional]][y])\n",
    "        featuresOdds.append(prob)\n",
    "        featuresOdds.sort(reverse=True)\n",
    "    # util.raiseNotDefined()\n",
    "\n",
    "    return featuresOdds\n",
    "    \n",
    "\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f8045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains feature extraction methods and harness \n",
    "# code for data classification\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "TEST_SET_SIZE = 100\n",
    "DIGIT_DATUM_WIDTH=28\n",
    "DIGIT_DATUM_HEIGHT=28\n",
    "FACE_DATUM_WIDTH=60\n",
    "FACE_DATUM_HEIGHT=70\n",
    "\n",
    "\n",
    "def basicFeatureExtractorDigit(datum):\n",
    "  \"\"\"\n",
    "  Returns a set of pixel features indicating whether\n",
    "  each pixel in the provided datum is white (0) or gray/black (1)\n",
    "  \"\"\"\n",
    "  a = datum.getPixels()\n",
    "\n",
    "  features = Counter()\n",
    "  for x in range(DIGIT_DATUM_WIDTH):\n",
    "    for y in range(DIGIT_DATUM_HEIGHT):\n",
    "      if datum.getPixel(x, y) > 0:\n",
    "        features[(x,y)] = 1\n",
    "      else:\n",
    "        features[(x,y)] = 0\n",
    "  return features\n",
    "\n",
    "\n",
    "def analysis(classifier, guesses, testLabels, testData, rawTestData, printImage):\n",
    "  \"\"\"\n",
    "  This function is called after learning.\n",
    "  Include any code that you want here to help you analyze your results.\n",
    "  \n",
    "  Use the printImage(<list of pixels>) function to visualize features.\n",
    "  \n",
    "  An example of use has been given to you.\n",
    "  \n",
    "  - classifier is the trained classifier\n",
    "  - guesses is the list of labels predicted by your classifier on the test set\n",
    "  - testLabels is the list of true labels\n",
    "  - testData is the list of training datapoints (as Counter of features)\n",
    "  - rawTestData is the list of training datapoints (as Datum)\n",
    "  - printImage is a method to visualize the features \n",
    "  (see its use in the odds ratio part in runClassifier method)\n",
    "  \n",
    "  This code won't be evaluated. It is for your own optional use\n",
    "  (and you can modify the signature if you want).\n",
    "  \"\"\"\n",
    "  \n",
    "  # Put any code here...\n",
    "  # Example of use:\n",
    "  for i in range(len(guesses)):\n",
    "      prediction = guesses[i]\n",
    "      truth = testLabels[i]\n",
    "      if (prediction != truth):\n",
    "          print(\"===================================\")\n",
    "          print(\"Mistake on example %d\" % i) \n",
    "          print(\"Predicted %d; truth is %d\" % (prediction, truth))\n",
    "          print(\"Image: \")\n",
    "          print(rawTestData[i])\n",
    "          break\n",
    "\n",
    "\n",
    "## =====================\n",
    "## You don't have to modify any code below.\n",
    "## =====================\n",
    "\n",
    "\n",
    "class ImagePrinter:\n",
    "    def __init__(self, width, height):\n",
    "      self.width = width\n",
    "      self.height = height\n",
    "\n",
    "def default(str):\n",
    "  return str + ' [Default: %default]'\n",
    "\n",
    "\n",
    "def readCommand( argv ):\n",
    "  \"Processes the command used to run from the command line.\"\n",
    "  from optparse import OptionParser  \n",
    "  parser = OptionParser()\n",
    "  \n",
    "  parser.add_option('-c', '--classifier', help=default('The type of classifier'), choices=['mostFrequent', 'nb', 'naiveBayes', 'perceptron', 'mira', 'minicontest'], default='mostFrequent')\n",
    "  parser.add_option('-d', '--data', help=default('Dataset to use'), choices=['digits', 'faces'], default='digits')\n",
    "  parser.add_option('-t', '--training', help=default('The size of the training set'), default=100, type=\"int\")\n",
    "  parser.add_option('-a', '--autotune', help=default(\"Whether to automatically tune hyperparameters\"), default=False, action=\"store_true\")\n",
    "  parser.add_option('-i', '--iterations', help=default(\"Maximum iterations to run training\"), default=3, type=\"int\")\n",
    "\n",
    "  options, otherjunk = parser.parse_args(argv)\n",
    "  if len(otherjunk) != 0: raise Exception('Command line input not understood: ' + str(otherjunk))\n",
    "  args = {}\n",
    "  \n",
    "  # Set up variables according to the command line input.\n",
    "  print(\"Doing classification\")\n",
    "  print(\"--------------------\")\n",
    "  print(\"data:\\t\\t\" + options.data)\n",
    "  print(\"classifier:\\t\\t\" + options.classifier)\n",
    "  print(\"training set size:\\t\" + str(options.training))\n",
    "  if(options.data==\"digits\"):\n",
    "    printImage = ImagePrinter(DIGIT_DATUM_WIDTH, DIGIT_DATUM_HEIGHT)\n",
    "    featureFunction = basicFeatureExtractorDigit    \n",
    "  else:\n",
    "    print(\"Unknown dataset\", options.data)\n",
    "    print(USAGE_STRING)\n",
    "    sys.exit(2)\n",
    "    \n",
    "  if(options.data==\"digits\"):\n",
    "    legalLabels = list(range(10))\n",
    "  else:\n",
    "    legalLabels = list(range(2))\n",
    "    \n",
    "  if options.training <= 0:\n",
    "    print(\"Training set size should be a positive integer (you provided: %d)\" % options.training)\n",
    "    print(USAGE_STRING)\n",
    "    sys.exit(2)\n",
    "\n",
    "  if(options.classifier == \"mostFrequent\"):\n",
    "    classifier = MostFrequentClassifier(legalLabels)\n",
    "  elif(options.classifier == \"naiveBayes\" or options.classifier == \"nb\"):\n",
    "    classifier = NaiveBayesClassifier(legalLabels)\n",
    "    if (options.autotune):\n",
    "        print(\"using automatic tuning for naivebayes\")\n",
    "        classifier.automaticTuning = True\n",
    "  else:\n",
    "    print(\"Unknown classifier:\", options.classifier)\n",
    "    print(USAGE_STRING)\n",
    "    \n",
    "    sys.exit(2)\n",
    "\n",
    "  args['classifier'] = classifier\n",
    "  args['featureFunction'] = featureFunction\n",
    "  args['printImage'] = printImage\n",
    "  \n",
    "  return args, options\n",
    "\n",
    "USAGE_STRING = \"\"\"\n",
    "USAGE:      python dataClassifier.py <options>\n",
    "EXAMPLES:   (1) python dataClassifier.py\n",
    "                  - trains the default mostFrequent classifier on the digit dataset\n",
    "                  using the default 100 training examples and\n",
    "                  then test the classifier on test data\n",
    "                 \"\"\"    \n",
    "\n",
    "# Main harness code\n",
    "\n",
    "def runClassifier(args, options):\n",
    "  featureFunction = args['featureFunction']\n",
    "  classifier = args['classifier']\n",
    "  printImage = args['printImage']\n",
    "      \n",
    "  # Load data  \n",
    "  numTraining = options.training\n",
    "\n",
    "  rawTrainingData = loadDataFile(\"trainingimages\", numTraining,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "  trainingLabels = loadLabelsFile(\"traininglabels\", numTraining)\n",
    "  rawValidationData = loadDataFile(\"validationimages\", TEST_SET_SIZE,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "  validationLabels = loadLabelsFile(\"validationlabels\", TEST_SET_SIZE)\n",
    "  rawTestData = loadDataFile(\"testimages\", TEST_SET_SIZE,DIGIT_DATUM_WIDTH,DIGIT_DATUM_HEIGHT)\n",
    "  testLabels = loadLabelsFile(\"testlabels\", TEST_SET_SIZE)\n",
    "    \n",
    "  \n",
    "  # Extract features\n",
    "  print(\"Extracting features...\")\n",
    "  trainingData = list(map(featureFunction, rawTrainingData))\n",
    "  validationData = list(map(featureFunction, rawValidationData))\n",
    "  testData = list(map(featureFunction, rawTestData))\n",
    "  \n",
    "  # Conduct training and testing\n",
    "  print(\"Training...\")\n",
    "  classifier.train(trainingData, trainingLabels, validationData, validationLabels)\n",
    "  print(\"Validating...\")\n",
    "  guesses = classifier.classify(validationData)\n",
    "  correct = [guesses[i] == validationLabels[i] for i in range(len(validationLabels))].count(True)\n",
    "  print(str(correct), (\"correct out of \" + str(len(validationLabels)) + \" (%.1f%%).\") % (100.0 * correct / len(validationLabels)))\n",
    "  print(\"Testing...\")\n",
    "  guesses = classifier.classify(testData)\n",
    "  correct = [guesses[i] == testLabels[i] for i in range(len(testLabels))].count(True)\n",
    "  print(str(correct), (\"correct out of \" + str(len(testLabels)) + \" (%.1f%%).\") % (100.0 * correct / len(testLabels)))\n",
    "  analysis(classifier, guesses, testLabels, testData, rawTestData, printImage)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   # Read input\n",
    "#   args, options = readCommand( sys.argv[1:] ) \n",
    "#   # Run classifier\n",
    "#   runClassifier(args, options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820b8225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing classification\n",
      "--------------------\n",
      "data:\t\tdigits\n",
      "classifier:\t\tnaiveBayes\n",
      "training set size:\t100\n",
      "using automatic tuning for naivebayes\n",
      "Extracting features...\n",
      "Training...\n",
      "Validating...\n",
      "74 correct out of 100 (74.0%).\n",
      "Testing...\n",
      "65 correct out of 100 (65.0%).\n",
      "===================================\n",
      "Mistake on example 3\n",
      "Predicted 3; truth is 5\n",
      "Image: \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "          +#########+       \n",
      "         +###########+      \n",
      "         ############+      \n",
      "         ############       \n",
      "         ####+++#####       \n",
      "         +##+     +++       \n",
      "         +###++++           \n",
      "          ########+         \n",
      "          #########+        \n",
      "          ##########+       \n",
      "          +##########       \n",
      "           +++  ++###+      \n",
      "                  +###      \n",
      "      ++           ###      \n",
      "     +###++       +###      \n",
      "      ######++   +###+      \n",
      "      ++#############       \n",
      "       ++###########+       \n",
      "         +#########+        \n",
      "           ++####++         \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "# args = ['-c', 'naiveBayes', '--autotune']\n",
    "# options = {'classifier': 'naiveBayes', 'data': 'digits', 'training': 100, 'autotune': True, 'iterations': 3}\n",
    "\n",
    "args, options = readCommand(['-c', 'naiveBayes', '--autotune'])\n",
    "\n",
    "runClassifier(args, options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd675a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing classification\n",
      "--------------------\n",
      "data:\t\tdigits\n",
      "classifier:\t\tnaiveBayes\n",
      "training set size:\t1000\n",
      "using automatic tuning for naivebayes\n",
      "Extracting features...\n",
      "Training...\n",
      "Validating...\n",
      "82 correct out of 100 (82.0%).\n",
      "Testing...\n",
      "78 correct out of 100 (78.0%).\n",
      "===================================\n",
      "Mistake on example 3\n",
      "Predicted 3; truth is 5\n",
      "Image: \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "          +#########+       \n",
      "         +###########+      \n",
      "         ############+      \n",
      "         ############       \n",
      "         ####+++#####       \n",
      "         +##+     +++       \n",
      "         +###++++           \n",
      "          ########+         \n",
      "          #########+        \n",
      "          ##########+       \n",
      "          +##########       \n",
      "           +++  ++###+      \n",
      "                  +###      \n",
      "      ++           ###      \n",
      "     +###++       +###      \n",
      "      ######++   +###+      \n",
      "      ++#############       \n",
      "       ++###########+       \n",
      "         +#########+        \n",
      "           ++####++         \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "args, options = readCommand(['-d', 'digits', '-c', 'naiveBayes', '-a', '-t', '1000'])\n",
    "\n",
    "runClassifier(args, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08a2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
